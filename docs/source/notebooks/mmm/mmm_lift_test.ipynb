{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "258ff2e5",
   "metadata": {},
   "source": [
    "(mmm_lift_test)=\n",
    "\n",
    "# Lift Test Calibration\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You may have heard of the phrase \"[All models are wrong but some are useful.](https://en.wikipedia.org/wiki/All_models_are_wrong)\" This is true in many areas, and it's likely that after the first attempt, you haven't yet created a model that can accurately determine your true attribution. Even if you have, how can you be sure? We create models to understand the attribution of our marketing channels, but it appears that even then, we can't always rely on what the models tell us.\n",
    "\n",
    "In order to ensure that our models are decomposing correctly, we can use various testing methods to gather real-world data and compare it with our models. This will help us to identify any discrepancies and improve the decomposition accuracy of our models. \n",
    "\n",
    "Today, we will explore a new way to integrate experiments into **pymc-marketing**. This will bring us closer to accurate representations of real-world values and improve the estimates generated by our models.\n",
    "\n",
    "## When are lifts test useful?\n",
    "\n",
    "In some situations, all of the relevant experiment spend data is captured within historical data that you will including in your training set. In these cases, a valid approach could be to simply train your MMM on all available data (including experiment and non-experiment periods) in order to optimally inform you about model parameters and ultimately get better insights. However there are a number of situations when this approach will not be appropriate.\n",
    "\n",
    "1. Imagine your online advertising platform gave you additional credit. You decide to spend this credit by increasing activity on a digital ad channel and you want to use this as a way to evaluate the uplift. In this situation, you will have increased the level of advertising taking place, but this 'increased spend' is not charged to your invoice. So unless your data pipeline is really on point, your spend data will not accurately reflect the level of effective spend.\n",
    "\n",
    "2. You want to run a test on TV. In that case, you probably have to pay months before the test takes place or the commercial is aired. So, your spending may be in February and the action in March, but during the period of the experiment itself, there is no spending. Here, the spend may well be contained in your training data, but the time lag between the spend and the advertising takes place is very high. So the adstock function which accommodates short term lag effects may not adequately capture longer term lags such as this.\n",
    "\n",
    "3. You are experimenting with discounts or promotions. These might be quantifiable, but not show up in your traditional media spend channels and so your experimentation may not be captured by your MMM.\n",
    "\n",
    "These are just a few examples where lift tests can be useful. In these cases, you can use the results of the lift test to adjust the model parameters and improve the accuracy of the model.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "Today, we won't be discussing how to conduct lift tests, but instead, we will focus on their utilization. If you wish to acquire knowledge on how to generate results that are compatible with your MMM models, you can check out [CausalPy](https://causalpy.readthedocs.io/en/latest/) for conducting experiments.\n",
    "\n",
    "## Goal\n",
    "\n",
    "After reading this notebook, you will have gained the necessary expertise to incorporate the results (detected uplift from your experiments) into our regressive model.\n",
    "\n",
    "This notebook will display using the `add_lift_test_measurements` method of `MMM` and its workflow:\n",
    "\n",
    "1. Build model: `mmm.build_model(X, y)`\n",
    "2. Add lift measurements: `mmm.add_lift_test_measurements(df_lift_test)`\n",
    "2. Sample posterior: `mmm.fit(X, y)`\n",
    "\n",
    "This is a case study of two correlated channels to see how lift tests help distinguish the channel effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c60cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import seaborn as sns\n",
    "\n",
    "from pymc_marketing.mmm import MMM, GeometricAdstock, LogisticSaturation\n",
    "from pymc_marketing.mmm.transformers import logistic_saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba181a-642f-4def-9eb9-c90235352f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 7]\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e711b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = sum(map(ord, \"Lift tests help distinguish channel effects\"))\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540a1f69",
   "metadata": {},
   "source": [
    "## Generate Correlated Spends and Model Target\n",
    "\n",
    "First we'll generate synthetic data for two channels with completely correlated spends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a00d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dates = 52\n",
    "dates = pd.date_range(start=\"2024-01-01\", periods=n_dates, freq=\"W-MON\")\n",
    "spend_rv = pm.Uniform.dist(lower=0.1, upper=1, size=n_dates)\n",
    "spend = pm.draw(spend_rv, random_seed=rng)\n",
    "spend1 = spend / spend.max()\n",
    "spend2 = spend - 0.05\n",
    "spend2 /= spend2.max()\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"date\": dates,\n",
    "        \"channel 1\": spend1,\n",
    "        \"channel 2\": spend2,\n",
    "    }\n",
    ")\n",
    "\n",
    "ax = df.set_index(\"date\").plot(ylabel=\"channel spend\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b392fe2",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "For this example, the synthetic spend data is not produced in a overly realistic manner. However, we have normalized the maxmium spend to 1 for each channel to mimmick data pre-processing that typically takes place in a pymc-marketing workflow.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74c015",
   "metadata": {},
   "source": [
    "We can double check that the to channels are perfectly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f86a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(regex=\"channel\").corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ea5d3-ed18-48ad-9bfe-2ba395c90a11",
   "metadata": {},
   "source": [
    "We use the `MMM` class to specify our model just as usual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmm = MMM(\n",
    "    date_column=\"date\",\n",
    "    channel_columns=[\"channel 1\", \"channel 2\"],\n",
    "    adstock=GeometricAdstock(l_max=6),\n",
    "    saturation=LogisticSaturation(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0d5149",
   "metadata": {},
   "source": [
    "For this constructed example, we will set parameter of the model with the `pm.do` operator and take a random sample of the target variable. The fixed parameters are below which we will try to recover.\n",
    "\n",
    "At this point, a model has not been fit. However, we have created our data set to fit our model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbadef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_lam_c1 = 10\n",
    "true_beta_c1 = 0.55\n",
    "\n",
    "true_lam_c2 = 1.5\n",
    "true_beta_c2 = 1.0\n",
    "\n",
    "true_params = {\n",
    "    \"adstock_alpha\": [0.5, 0.5],\n",
    "    \"saturation_lam\": [true_lam_c1, true_lam_c2],\n",
    "    \"saturation_beta\": [true_beta_c1, true_beta_c2],\n",
    "    \"intercept\": 0.5,\n",
    "    \"y_sigma\": 0.25,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c4dd48",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "mmm.build_model(df.reset_index(), y=np.ones(n_dates))\n",
    "fixed_model = pm.do(mmm.model, true_params)\n",
    "df[\"y\"] = pm.draw(fixed_model[\"y\"], random_seed=rng)\n",
    "del mmm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.set_index(\"date\").plot(ylabel=\"\", title=\"Channel spends and target variable\")\n",
    "ax.legend(bbox_to_anchor=(1.0, 1.05), title=\"column\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e33d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.reset_index().drop(\"y\", axis=1)\n",
    "y = df[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23a0fff-08d9-48de-bc3a-76538d0f0c5d",
   "metadata": {},
   "source": [
    "## Indistinguishable Parameter Estimates\n",
    "\n",
    "In order to show the trouble that completely correlated channels provides, let's fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eede02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_kwargs = {\"nuts_sampler\": \"numpyro\", \"random_seed\": rng}\n",
    "\n",
    "idata_without = mmm.fit(X, y, **fit_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c1de0",
   "metadata": {},
   "source": [
    "Since the spends are completely correlated, there is no way to distinguish the parameters. Not only that, but the parameter estimates are not close to actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4460ac86-0314-4724-beab-f949c6a09814",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_true_value(value, channel: str, ax: plt.Axes, split: float = 0.42) -> plt.Axes:\n",
    "    top = 2 * split\n",
    "    ymin, ymax = (0, split) if channel == \"channel 2\" else (split, top)\n",
    "    ax.axvline(value, ymin=ymin, ymax=ymax, color=\"black\", linestyle=\"dashed\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b939122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_forest(idata_without, var_names=[\"saturation_lam\"], combined=True)[0]\n",
    "\n",
    "plot_true_value(true_lam_c1, \"channel 1\", ax=ax, split=0.4)\n",
    "plot_true_value(true_lam_c2, \"channel 2\", ax=ax, split=0.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7cc996",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_forest(idata_without, var_names=[\"saturation_beta\"], combined=True)[0]\n",
    "\n",
    "plot_true_value(true_beta_c1, \"channel 1\", ax=ax, split=0.4)\n",
    "plot_true_value(true_beta_c2, \"channel 2\", ax=ax, split=0.4);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db6b5e-0a6d-469d-b8d2-72b96312eb72",
   "metadata": {},
   "source": [
    "We can also witness that while the actual saturation curves are different (because we specified the true parameters for each channel), the MMM is unable to distinguish between the two channels.\n",
    "\n",
    "We can show this below by plotting the actual saturation curves (lines) and the direct response curves (points).\n",
    "\n",
    ":::{admonition} Direct response curves\n",
    ":class: note\n",
    "\n",
    "Plots the direct contribution curves for each marketing channel. The term \"direct\" refers to the fact we plot costs vs immediate returns and we do not take into account the lagged effects of the channels e.g. adstock transformations. And so these curves will actually consist of a series of points, each representing the direct contribution of a spend level.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436df91b",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def saturation_function(x, lam, beta):\n",
    "    return (beta * logistic_saturation(x, lam)).eval()\n",
    "\n",
    "\n",
    "step_size = 0.05\n",
    "xx = np.arange(0, spend.max() * 1.1, step_size)\n",
    "\n",
    "c1_curve_fn = partial(saturation_function, lam=true_lam_c1, beta=true_beta_c1)\n",
    "c2_curve_fn = partial(saturation_function, lam=true_lam_c2, beta=true_beta_c2)\n",
    "\n",
    "c1_curve = c1_curve_fn(xx)\n",
    "c2_curve = c2_curve_fn(xx)\n",
    "\n",
    "\n",
    "def plot_actual_curves(ax: plt.Axes, linestyle: str | None = None) -> plt.Axes:\n",
    "    ax.plot(xx, c1_curve, label=\"channel 1\", color=\"C0\", linestyle=linestyle)\n",
    "    ax.plot(xx, c2_curve, label=\"channel 2\", color=\"C1\", linestyle=linestyle)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_reference(ax: plt.Axes) -> plt.Axes:\n",
    "    ax.plot(xx, xx, label=\"y=x\", color=\"black\", linestyle=\"--\")\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043353b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = mmm.plot_direct_contribution_curves(same_axes=True)\n",
    "ax = fig.axes[0]\n",
    "plot_actual_curves(ax=ax, linestyle=\"dashed\")\n",
    "ax.figure.suptitle(\n",
    "    \"Direct response curves (points) and actual saturation curves (dashed lines)\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc9e02",
   "metadata": {},
   "source": [
    "We can see that the true but latent saturation curves (dashed lines) for each channel are different, but that the the MMM is unable to distinguish that the saturation curves for each channel (points) are different. And this is because the spends are perfectly correlated. \n",
    "\n",
    "Let's see if we can improve upon this by adding lift test measurements.\n",
    "\n",
    ":::{note}\n",
    "In order to avoid confusion with the plot above, the actual saturation curves are represented by the dashed lines, while the direct contribution curves are represented by the points. If lift tests can help us in this situation of high spend correlation, then we should be able to detect this by: a) achieving better parameter estimates, and b) correspondingly, getting better estimates of the saturation curves.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11945db5",
   "metadata": {},
   "source": [
    "We can also visualize the channel contributions over time. The wide HDI's in the plot below shows that we have considerable uncertainty in the channel contributions. We can also see that the posterior means of the channel contributions are quite far off the mark of the actual channel contributions. Again, these true channel contributions are only known to us in this synthetic data example and would not be available to us in a real world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302995b6",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from pymc_marketing.mmm.transformers import geometric_adstock\n",
    "\n",
    "\n",
    "def calculate_true_channel_contribitions(df, true_params):\n",
    "    # apply geometric adstock transformation\n",
    "    df[\"x1_adstock\"] = (\n",
    "        geometric_adstock(\n",
    "            x=df[\"channel 1\"].to_numpy(),\n",
    "            alpha=true_params[\"adstock_alpha\"][0],\n",
    "            l_max=8,\n",
    "            normalize=True,\n",
    "        )\n",
    "        .eval()\n",
    "        .flatten()\n",
    "    )\n",
    "    df[\"x2_adstock\"] = (\n",
    "        geometric_adstock(\n",
    "            x=df[\"channel 2\"].to_numpy(),\n",
    "            alpha=true_params[\"adstock_alpha\"][1],\n",
    "            l_max=8,\n",
    "            normalize=True,\n",
    "        )\n",
    "        .eval()\n",
    "        .flatten()\n",
    "    )\n",
    "\n",
    "    # apply saturation transformation\n",
    "    df[\"x1_adstock_saturated\"] = logistic_saturation(\n",
    "        x=df[\"x1_adstock\"].to_numpy(), lam=true_params[\"saturation_lam\"][0]\n",
    "    ).eval()\n",
    "\n",
    "    df[\"x2_adstock_saturated\"] = logistic_saturation(\n",
    "        x=df[\"x2_adstock\"].to_numpy(), lam=true_params[\"saturation_lam\"][1]\n",
    "    ).eval()\n",
    "    return df\n",
    "\n",
    "\n",
    "df = calculate_true_channel_contribitions(df, true_params)\n",
    "\n",
    "\n",
    "def plot_channel_contributions(mmm, df):\n",
    "    channels_contribution_original_scale = (\n",
    "        mmm.compute_channel_contribution_original_scale()\n",
    "    )\n",
    "    channels_contribution_original_scale_hdi = az.hdi(\n",
    "        ary=channels_contribution_original_scale\n",
    "    )\n",
    "\n",
    "    get_mean_contributions_over_time_df = mmm.compute_mean_contributions_over_time(\n",
    "        original_scale=True\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        nrows=2,\n",
    "        figsize=(15, 8),\n",
    "        ncols=1,\n",
    "        sharex=True,\n",
    "        sharey=False,\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "\n",
    "    for i, x in enumerate([\"channel 1\", \"channel 2\"]):\n",
    "        # Estimate true contribution in the original scale from the data generating process\n",
    "        sns.lineplot(\n",
    "            x=df[\"date\"],\n",
    "            y=true_params[\"saturation_beta\"][i]\n",
    "            * df[f\"x{i + 1}_adstock_saturated\"],  # ??????\n",
    "            color=\"black\",\n",
    "            label=f\"{x} true contribution\",\n",
    "            ax=ax[i],\n",
    "        )\n",
    "        # HDI estimated contribution in the original scale\n",
    "        ax[i].fill_between(\n",
    "            x=df[\"date\"],\n",
    "            y1=channels_contribution_original_scale_hdi.sel(channel=x)[\"x\"][:, 0],\n",
    "            y2=channels_contribution_original_scale_hdi.sel(channel=x)[\"x\"][:, 1],\n",
    "            color=f\"C{i}\",\n",
    "            label=rf\"{x} $94\\%$ HDI contribution\",\n",
    "            alpha=0.4,\n",
    "        )\n",
    "        # Mean estimated contribution in the original scale\n",
    "        sns.lineplot(\n",
    "            x=df[\"date\"],\n",
    "            y=get_mean_contributions_over_time_df[x].to_numpy(),\n",
    "            color=f\"C{i}\",\n",
    "            label=f\"{x} posterior mean contribution\",\n",
    "            alpha=0.8,\n",
    "            ax=ax[i],\n",
    "        )\n",
    "        ax[i].legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "        ax[i].set(title=x, ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153541ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channel_contributions(mmm, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632022b0",
   "metadata": {},
   "source": [
    "## About Lift Tests\n",
    "\n",
    "In a lift study, one temporarily changes the budget of a channel for a fixed period of time, and then uses some method (for example CausalPy) to make inference about the change in sales directly caused by the adjustment.\n",
    "\n",
    "A lift test is characterized by:\n",
    "\n",
    "- `channel`: the channel that was tested\n",
    "- `x`: pre-test channel spend\n",
    "- `delta_x`: change made to `x`\n",
    "- `delta_y`: inferred change in sales due to `delta_x`\n",
    "- `sigma`: standard deviation of `delta_y`\n",
    "\n",
    "An experiment characterized in this way can be viewed as two points on the saturation curve for the channel. Accordingly, lift test calibration is implemented by adding a term to the model likelihood, that makes the channel saturation curve (the contribution as a function of spend) align with the test observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c15c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lift_test_from_actual_curve(\n",
    "    channel: str, x: float, delta_x: float, sigma: float\n",
    ") -> dict[str, float]:\n",
    "    curve_fn = c1_curve_fn if channel == \"channel 1\" else c2_curve_fn\n",
    "    delta_y = curve_fn(x + delta_x) - curve_fn(x)\n",
    "\n",
    "    return {\n",
    "        \"channel\": channel,\n",
    "        \"x\": x,\n",
    "        \"delta_x\": delta_x,\n",
    "        \"delta_y\": delta_y,\n",
    "        \"sigma\": sigma,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a624d-c3b5-4b37-9812-d772a3e1c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lift_test = pd.DataFrame(\n",
    "    [\n",
    "        # Channel x1\n",
    "        create_lift_test_from_actual_curve(\"channel 1\", 0.05, 0.05, 0.05),\n",
    "        create_lift_test_from_actual_curve(\"channel 1\", 0.15, 0.05, 0.05),\n",
    "        create_lift_test_from_actual_curve(\"channel 1\", 0.3, -0.05, 0.05),\n",
    "        # Channel x2\n",
    "        create_lift_test_from_actual_curve(\"channel 2\", 0.5, 0.05, 0.10),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_lift_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb64a7ac",
   "metadata": {},
   "source": [
    "Let's visualise the lift test results to get an understanding of how they can better inform the model parameters - specifically the saturation curve parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ae1ac-c005-4c71-8bfa-1e33bf3b0d4f",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_triangle(\n",
    "    x,\n",
    "    delta_x,\n",
    "    delta_y,\n",
    "    color: str,\n",
    "    ax: plt.Axes,\n",
    "    offset: float = 0,\n",
    "    label: str | None = None,\n",
    ") -> plt.Axes:\n",
    "    x_after = x + delta_x\n",
    "\n",
    "    y = offset\n",
    "    y_after = y + delta_y\n",
    "\n",
    "    ax.plot([x, x_after], [y, y], color=color, label=label)\n",
    "    ax.plot([x_after, x_after], [y, y_after], color=color)\n",
    "    ax.plot([x, x_after], [y, y_after], color=color, linestyle=\"dashed\")\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_channel_triangles(\n",
    "    df: pd.DataFrame, color: str, ax: plt.Axes, label: str\n",
    ") -> plt.Axes:\n",
    "    kwargs = {\"label\": label}\n",
    "    for _, row in df.iterrows():\n",
    "        plot_triangle(\n",
    "            row[\"x\"], row[\"delta_x\"], row[\"delta_y\"], ax=ax, color=color, **kwargs\n",
    "        )\n",
    "        if \"label\" in kwargs:\n",
    "            kwargs.pop(\"label\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_lift_test_triangles(df: pd.DataFrame, ax: plt.Axes) -> plt.Axes:\n",
    "    idx = df[\"channel\"] == \"channel 1\"\n",
    "    plot_channel_triangles(df.loc[idx], color=\"C0\", ax=ax, label=\"channel 1\")\n",
    "    plot_channel_triangles(df.loc[~idx], color=\"C1\", ax=ax, label=\"channel 2\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "# UPPER PLOT\n",
    "plot_actual_curves(ax=ax[0], linestyle=\"dashed\")\n",
    "\n",
    "# iterate over rows in df_lift_test\n",
    "for _, row in df_lift_test.iterrows():\n",
    "    curve_fn = c1_curve_fn if row[\"channel\"] == \"channel 1\" else c2_curve_fn\n",
    "    plot_triangle(\n",
    "        row[\"x\"],\n",
    "        row[\"delta_x\"],\n",
    "        row[\"delta_y\"],\n",
    "        ax=ax[0],\n",
    "        color=\"C0\" if row[\"channel\"] == \"channel 1\" else \"C1\",\n",
    "        label=f\"{row['channel']} lift test\",\n",
    "        offset=curve_fn(row[\"x\"]),\n",
    "    )\n",
    "\n",
    "ax[0].set(\n",
    "    ylabel=\"Contribution\",\n",
    "    title=\"Lift tests results shown on top of actual curves\",\n",
    ")\n",
    "\n",
    "# LOWER PLOT\n",
    "plot_lift_test_triangles(df_lift_test, ax=ax[1])\n",
    "ax[1].legend()\n",
    "ax[1].set(\n",
    "    xlim=(-0.01, 1.01),\n",
    "    xlabel=\"x\",\n",
    "    ylabel=\"change in channel contribution\",\n",
    "    title=\"Lift tests show different diminishing returns\",\n",
    ")\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9a6838-fca4-4185-83de-f331f8f2d8e0",
   "metadata": {},
   "source": [
    "The top plot shows the results superimposed upon the actual saturation curves. In a real situation we would not know the actual saturation curves, but the plot here is incuded to aid understanding of what is taking place.\n",
    "\n",
    "The bottom plot shows the same results but at y=0, focussing on the fact that we are only observing the _change_ in contribution. This is more true of the partial knowledge you'd have in a real situation.\n",
    "\n",
    "Lift tests are visualized with the triangles. The base of the triangle shows the change in the spend and height of triangle is change in contribution. \n",
    "\n",
    "While we only have the information in the bottom plot, the top plot shows how the lift test information can be used to help better estimate the saturation curves.\n",
    "\n",
    "For example, just from the lift tests (bottom triangles) we can see that channel 2 is slower to saturate than channel 1 because we get a higher change in contribution at higher spend levels.\n",
    "\n",
    ":::{note}\n",
    "The first 2 lift tests on channel 1 involved _increasing_ the spend on that channel. However the third lift test on channel 1 involved a _decrease_ in the spend. It is useful to be able to consider both increases and decreases in spend in lift tests. And there is nothing getting in the way of making this decrease even more extreme by temporarily setting the spend to zero.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197fbc8-2271-4f98-acd7-8026f7d64cf7",
   "metadata": {},
   "source": [
    "## Add Lift Tests to Model\n",
    "\n",
    "Having created a `MMM` model instance, `mmm` and built it using the `build_model` method or fit with `fit` method, we can add lift test results to the model using the `add_lift_test_measurments` method.\n",
    "\n",
    "First, let's take a look at the model graph before adding the lift test measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e582de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmm.graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab16c991",
   "metadata": {},
   "source": [
    "And now we'll add the lift test measurements to the model and see how our model graph has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68062b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmm.add_lift_test_measurements(df_lift_test)\n",
    "\n",
    "mmm.graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473c7d9-89ce-4210-9ead-c98efd1a8c1f",
   "metadata": {},
   "source": [
    "We can see the model graph is modified with new observation for our lift measurements. The observation distribution is assumed to be `Gamma` as each saturation curve is monotonically increasing given a set of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a29bf",
   "metadata": {},
   "source": [
    "In short, this works by providing a new likelihood term of the form\n",
    "\n",
    "$$\n",
    "\\mathrm{Gamma}(|\\Delta_y| ; \\mu = |\\tilde{\\text{lift}}|, \\sigma = \\sigma)\n",
    "$$\n",
    "\n",
    "where:\n",
    "* $|\\Delta_y|$ is the observed absolute change in contribution - as estimate from the lift test.\n",
    "* $|\\tilde{\\text{lift}}|$ is the absolute change in contribution as estimated by the model, i.e. based on the parameterized saturation curve.\n",
    "* $\\sigma$ is the standard deviation of the increase in $\\Delta_y$ of lift test. That is, we have uncertainty in the result of the lift test, and $\\sigma$ represents the standard deviation of this uncertainty. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52945ee4",
   "metadata": {},
   "source": [
    "We can refit the model but with the lift tests included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611feff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata_with = mmm.fit(X, y, **fit_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59944205",
   "metadata": {},
   "source": [
    "The model gets shaped by the lift test measurements and the response curves begin to separate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53303a65",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_channel_rug(\n",
    "    df: pd.DataFrame, color: str, ax: plt.Axes, height: float\n",
    ") -> plt.Axes:\n",
    "    for x in df[\"x\"].to_numpy():\n",
    "        ax.axvline(x, ymin=0, ymax=height, color=color)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_lift_test_rug(df, ax, height: float = 0.05) -> plt.Axes:\n",
    "    idx = df[\"channel\"] == \"channel 1\"\n",
    "    plot_channel_rug(df.loc[idx], color=\"C0\", ax=ax, height=height)\n",
    "    plot_channel_rug(df.loc[~idx], color=\"C1\", ax=ax, height=height)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c528dd2f-55d0-4c4c-adb9-1491eaea4071",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = mmm.plot_direct_contribution_curves(same_axes=True)\n",
    "ax = fig.axes[0]\n",
    "plot_actual_curves(ax=ax, linestyle=\"dashed\")\n",
    "plot_lift_test_rug(df_lift_test, ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633ac3cd",
   "metadata": {},
   "source": [
    "The 'rug' marks in the plot above show the _initial_ channel spend before the lift test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af2d1b7",
   "metadata": {},
   "source": [
    "Below we show the (currently modest) changes in the saturation parameter estimates. The idea is that as we add more lift tests (see later), we can better estimate the saturation curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f446a",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_comparison(data, model_names, var_name: str) -> plt.Axes:\n",
    "    return az.plot_forest(\n",
    "        data,\n",
    "        model_names=model_names,\n",
    "        var_names=[var_name],\n",
    "        combined=True,\n",
    "        figsize=(8, 4),\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd102a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [idata_without, idata_with]\n",
    "model_names = [\"without lift tests\", \"with lift tests\"]\n",
    "\n",
    "ax = plot_comparison(data, model_names, \"saturation_lam\")\n",
    "plot_true_value(true_lam_c1, \"channel 1\", ax)\n",
    "plot_true_value(true_lam_c2, \"channel 2\", ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_comparison(data, model_names, \"saturation_beta\")\n",
    "plot_true_value(true_beta_c1, \"channel 1\", ax)\n",
    "plot_true_value(true_beta_c2, \"channel 2\", ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc568f0c",
   "metadata": {},
   "source": [
    "Careful examination of these 2 plots shows that the posterior mean has shifted closer to the true parameter value and/or the HDI is shrinking, indicating improved precision of our estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21b90ef",
   "metadata": {},
   "source": [
    "Let's return to our estimated channel contributions over time. The HDI's are narrower than before, indicating that we have reduced the uncertainty in our channel contribution estimates. Even more impressively, the posterior mean estimates are now much closer to the actual channel contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c71ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channel_contributions(mmm, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99ff28",
   "metadata": {},
   "source": [
    "## Add Additional Lift Tests\n",
    "\n",
    "We can add even more lift tests.\n",
    "\n",
    "They can either all be added at one time or separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb30705-46ec-4419-aeff-a430b3ae2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_lift_test = pd.DataFrame(\n",
    "    [\n",
    "        # More for Channel x1\n",
    "        create_lift_test_from_actual_curve(\"channel 1\", 0.1, 0.05, sigma=0.01),\n",
    "        create_lift_test_from_actual_curve(\"channel 1\", 0.5, 0.05, sigma=0.01),\n",
    "        # More for channel x2\n",
    "        create_lift_test_from_actual_curve(\"channel 2\", 0.3, 0.05, sigma=0.01),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_additional_lift_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d161e",
   "metadata": {},
   "source": [
    "Use the `name` parameter in order to separate the two sets of observations in the model graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88687fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmm.add_lift_test_measurements(df_additional_lift_test, name=\"more_lift_measurements\")\n",
    "\n",
    "mmm.graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c2eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata_with_more = mmm.fit(X, y, **fit_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00406304",
   "metadata": {},
   "source": [
    "The response curve is shifting more and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab57723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_lift_tests = pd.concat([df_lift_test, df_additional_lift_test])\n",
    "\n",
    "fig = mmm.plot_direct_contribution_curves(same_axes=True)\n",
    "ax = fig.axes[0]\n",
    "plot_actual_curves(ax=ax, linestyle=\"dashed\")\n",
    "plot_lift_test_rug(df_all_lift_tests, ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [idata_without, idata_with, idata_with_more]\n",
    "model_names = [\"without lift tests\", \"with lift tests\", \"with more lift tests\"]\n",
    "\n",
    "ax = plot_comparison(data, model_names, \"saturation_lam\")\n",
    "plot_true_value(true_lam_c1, \"channel 1\", ax, split=0.435)\n",
    "plot_true_value(true_lam_c2, \"channel 2\", ax, split=0.435);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b66cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_comparison(data, model_names, \"saturation_beta\")\n",
    "plot_true_value(true_beta_c1, \"channel 1\", ax, split=0.435)\n",
    "plot_true_value(true_beta_c2, \"channel 2\", ax, split=0.435);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58735e63",
   "metadata": {},
   "source": [
    "So we can see in the 2 plots above that when we add even more lift test data to our MMM, the parameter estimates relating to the saturation curves are getting closer to the true values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14430ce7",
   "metadata": {},
   "source": [
    "Now, for a final time, let's check in on our channel contributions over time. The HDI's are much narrower when we compare to the original model - adding a number of lift test results has reduced our uncertainty in our channel contribution estimates. And the posterior means are now much closer to the actual channel contributions compared to before we added the lift test data to the MMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channel_contributions(mmm, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689ba42-ec1a-4154-be91-274cd5ef0237",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The `add_lift_test_measurements` method can be used in order to incorporate experiments into our model likelihood and nudge the model parameters closer to the actuals in this example.\n",
    "\n",
    "Conducting various experiments for each channel at various spends will bring the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064e3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w -p pymc_marketing,pytensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7d3db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
